+++
aliases = []
date = 2022-03-20T15:30:00Z
description = "A framework to improve the effectiveness of reviews, and eventually improving the quality of work."
pageimage = ""
tags = ["Product", "Team", "Culture", "Draft"]
title = "[Draft] On Effective Reviews that Improve Quality of Work"
url = ""

+++
> FYI, this is a draft post; published to get it reviewed. If you found this via Skit Slack, leave your feedback/comments in the thread.

There is a new (2022) Netflix documentary on Boeing, "Downfall: The Case Against Boeing," have you seen it?

It looks into the events throughout the history of the company that led to the two crashes of 737 MAX aircraft, occurring within a short time span.

So, where did it go wrong?

In short, somewhere the company started ignoring its core values. It started nurturing an environment where the lousy quality of work wasn't called out.

But, how does it all connect with reviewing someone's work?

> As per Meta CTO Andrew Bosworth, reviews are a tool where you can collaboratively improve the quality of someone's (or your) work ([refer](https://boz.com/articles/reviews "On Reviews - Boz")).

If done right, they increase the mutual alignment towards the problem statement and provide a clear direction to strive for further excellence.

### How to review effectively?

Imagine one of the following scenarios as you find fit

* You're a PM reviewing the launch plan your APM has drafted
* You're a senior engineer reviewing a design document created by a team member
* You're a \[reviewer ...\] reviewing a \[creator's ...\] work

Here is a framework I've been practicing to increase the effectiveness, that involves **asking the** **following three** **questions** **to the creator**.

* It isn't recommended to ask them directly as a leading question, doing so might not get the all right answers.

### Question-1: What do you not like about the approach?

* As the IKEA effect goes, we are frequently biased towards our own work and it becomes important to acknowledge/prevent the bias.
* This confronting question is designed to \[over a period\] fine-tune the self-assessment muscle of the creator.
* Instead of asking this as a leading question, you can start with:
  * How can we make it even better?

### Question-2: What areas did you ignore while working on it?

* It's aimed to understand the areas of the problem statement that weren't addressed and can attack us going forward.
* Instead of asking this as a leading question, you can start with:
  * What would you do differently if given more time?

### Question-3: What constraints/assumptions did you work with?

* It's helpful to acknowledge that we're always in a constrained environment. It might be due to the timelines, dependencies, or many other factors.
* Identifying the constraints helps you get better at recognizing the [edge-cases](https://cdixon.org/2015/02/01/the-ai-startup-idea-maze "The idea maze for AI startups").

***

In summary, ask the following three questions to ensure you're adding value at the end of your review, without creating an analysis-paralysis situation.

1. What do you not like about the approach?
2. What areas did you ignore while working on it?
3. What constraints/assumptions did you work with?